import joblib
import numpy as np
import os
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

app = FastAPI()

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class TraceRequest(BaseModel):
    trace: list[float] 

MODEL_PATH = "model.pkl"
model = None
EXPECTED_LENGTH = None

# 1. Load Model & Determine Expected Size
if os.path.exists(MODEL_PATH):
    try:
        model = joblib.load(MODEL_PATH)
        # Random Forest stores the number of training features in n_features_in_
        if hasattr(model, "n_features_in_"):
            EXPECTED_LENGTH = model.n_features_in_
            print(f"âœ… Model loaded. Expecting input length: {EXPECTED_LENGTH}")
        else:
            print("âœ… Model loaded (Warning: Could not determine expected length)")
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
else:
    print(f"âš ï¸ WARNING: {MODEL_PATH} not found.")

def normalize_trace(trace, target_length):
    """
    Stretches or shrinks the input trace to match the target_length.
    """
    if target_length is None:
        return trace
        
    current_length = len(trace)
    if current_length == target_length:
        return trace
    
    # Interpolation: Create a new X-axis with 'target_length' points
    # and map the old values onto it.
    x_old = np.linspace(0, 1, current_length)
    x_new = np.linspace(0, 1, target_length)
    return np.interp(x_new, x_old, trace)

@app.post("/analyze")
def analyze_trace(request: TraceRequest):
    if model is None:
        raise HTTPException(status_code=500, detail="Model not loaded.")

    try:
        # 1. Get raw trace
        raw_trace = np.array(request.trace)
        
        # 2. FIX: Resize to match the model (589 -> 1000)
        if EXPECTED_LENGTH:
            clean_trace = normalize_trace(raw_trace, EXPECTED_LENGTH)
        else:
            clean_trace = raw_trace

        # 3. Reshape for Scikit-Learn (1 sample, N features)
        input_data = clean_trace.reshape(1, -1)
        
        # 4. Predict
        prediction = model.predict(input_data)[0]
        probabilities = model.predict_proba(input_data)
        confidence = np.max(probabilities)

        print(f"ðŸ” Trace resized ({len(raw_trace)}->{len(clean_trace)}). Prediction: {prediction} ({confidence:.2%})")

        return {
            "website": str(prediction),
            "confidence": float(confidence)
        }

    except Exception as e:
        print(f"ðŸ”¥ Prediction Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)